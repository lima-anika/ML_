{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10282641,"sourceType":"datasetVersion","datasetId":6363207}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anikalima/k-meanscluster?scriptVersionId=218349801\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install Pillow==4.0.0\n!pip install PIL\n!pip install image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:13:41.444713Z","iopub.execute_input":"2025-01-19T19:13:41.445002Z","iopub.status.idle":"2025-01-19T19:14:08.714294Z","shell.execute_reply.started":"2025-01-19T19:13:41.444973Z","shell.execute_reply":"2025-01-19T19:14:08.713188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\n%matplotlib inline\nplt.style.use(\"ggplot\")\n\nfrom skimage import io\nfrom skimage.io import imread, imshow\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.datasets import load_sample_image\nimport seaborn as sns; sns.set()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/kmeansimg'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:14:08.715336Z","iopub.execute_input":"2025-01-19T19:14:08.71563Z","iopub.status.idle":"2025-01-19T19:14:10.762361Z","shell.execute_reply.started":"2025-01-19T19:14:08.715609Z","shell.execute_reply":"2025-01-19T19:14:10.754417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Note: this requires the ``pillow`` package to be installed\ndog = imread('/kaggle/input/kmeansimg/seema/paharpur2.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(dog);\nprint(dog.shape)\nprint(dog.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:14:10.76397Z","iopub.execute_input":"2025-01-19T19:14:10.764407Z","iopub.status.idle":"2025-01-19T19:14:10.897262Z","shell.execute_reply.started":"2025-01-19T19:14:10.764382Z","shell.execute_reply":"2025-01-19T19:14:10.893253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imageio import imread\nimport matplotlib.pyplot as plt\n\ndog = imread('/kaggle/input/kmeansimg/seema/paharpur2.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(dog)\nprint(dog.shape)\nprint(dog.size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:14:29.579909Z","iopub.execute_input":"2025-01-19T19:14:29.5802Z","iopub.status.idle":"2025-01-19T19:14:29.602375Z","shell.execute_reply.started":"2025-01-19T19:14:29.580178Z","shell.execute_reply":"2025-01-19T19:14:29.601197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:14:37.768652Z","iopub.execute_input":"2025-01-19T19:14:37.768957Z","iopub.status.idle":"2025-01-19T19:14:42.343014Z","shell.execute_reply.started":"2025-01-19T19:14:37.768932Z","shell.execute_reply":"2025-01-19T19:14:42.342109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade scikit-image imageio matplotlib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:15:18.388808Z","iopub.execute_input":"2025-01-19T19:15:18.389167Z","iopub.status.idle":"2025-01-19T19:15:22.264589Z","shell.execute_reply.started":"2025-01-19T19:15:18.389121Z","shell.execute_reply":"2025-01-19T19:15:22.263505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import collections\nif not hasattr(collections, 'MutableMapping'):\n    import collections.abc\n    collections.MutableMapping = collections.abc.MutableMapping\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:16:10.617015Z","iopub.execute_input":"2025-01-19T19:16:10.617294Z","iopub.status.idle":"2025-01-19T19:16:10.621498Z","shell.execute_reply.started":"2025-01-19T19:16:10.617273Z","shell.execute_reply":"2025-01-19T19:16:10.620501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imageio import imread\nimport matplotlib.pyplot as plt\n\ndog = imread('/kaggle/input/kmeansimg/seema/paharpur2.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(dog)\nprint(dog.shape)\nprint(dog.size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:16:16.654809Z","iopub.execute_input":"2025-01-19T19:16:16.655085Z","iopub.status.idle":"2025-01-19T19:16:16.94808Z","shell.execute_reply.started":"2025-01-19T19:16:16.655066Z","shell.execute_reply":"2025-01-19T19:16:16.947238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fox = imread('/kaggle/input/kmeansimg/seema/banbibi_bharani_tiger.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(fox);\nprint(fox.shape)\nprint(fox.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:16:23.671224Z","iopub.execute_input":"2025-01-19T19:16:23.671512Z","iopub.status.idle":"2025-01-19T19:16:24.03778Z","shell.execute_reply.started":"2025-01-19T19:16:23.671489Z","shell.execute_reply":"2025-01-19T19:16:24.036801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lion = imread('/kaggle/input/kmeansimg/seema/Tiger.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(lion);\nprint(lion.shape)\nprint(lion.size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:16:30.249121Z","iopub.execute_input":"2025-01-19T19:16:30.249416Z","iopub.status.idle":"2025-01-19T19:16:31.851904Z","shell.execute_reply.started":"2025-01-19T19:16:30.249394Z","shell.execute_reply":"2025-01-19T19:16:31.850716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntiger = imread('/kaggle/input/kmeansimg/seema/Parliament_of_Bangladesh__front.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(tiger);\nprint(tiger.shape)\nprint(tiger.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:00.388628Z","iopub.execute_input":"2025-01-19T19:17:00.388931Z","iopub.status.idle":"2025-01-19T19:17:00.650576Z","shell.execute_reply.started":"2025-01-19T19:17:00.38891Z","shell.execute_reply":"2025-01-19T19:17:00.649726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wolf = imread('/kaggle/input/kmeansimg/seema/Nakshi_khata.JPG')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(wolf);\nprint(wolf.shape)\nprint(wolf.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:06.93399Z","iopub.execute_input":"2025-01-19T19:17:06.934328Z","iopub.status.idle":"2025-01-19T19:17:07.380966Z","shell.execute_reply.started":"2025-01-19T19:17:06.934306Z","shell.execute_reply":"2025-01-19T19:17:07.380179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"panda = imread('/kaggle/input/kmeansimg/seema/New_Year_celebration.jpg')\nax = plt.axes(xticks=[], yticks=[])\nax.imshow(panda);\nprint(panda.shape)\nprint(panda.size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:14.160857Z","iopub.execute_input":"2025-01-19T19:17:14.161168Z","iopub.status.idle":"2025-01-19T19:17:14.721577Z","shell.execute_reply.started":"2025-01-19T19:17:14.161145Z","shell.execute_reply":"2025-01-19T19:17:14.720559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dog.shape)  # Check the original dimensions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:22.883837Z","iopub.execute_input":"2025-01-19T19:17:22.884164Z","iopub.status.idle":"2025-01-19T19:17:22.888568Z","shell.execute_reply.started":"2025-01-19T19:17:22.884137Z","shell.execute_reply":"2025-01-19T19:17:22.887802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize the image to the target dimensions\ndog_resized = cv2.resize(dog, (271, 381))  # (width, height)\ndoggy = dog_resized.reshape(381 * 271, 3)\nprint(doggy.shape)  # Should output (103251, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:28.713649Z","iopub.execute_input":"2025-01-19T19:17:28.714063Z","iopub.status.idle":"2025-01-19T19:17:29.033338Z","shell.execute_reply.started":"2025-01-19T19:17:28.714026Z","shell.execute_reply":"2025-01-19T19:17:29.032451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"foxy = fox / 255.0 # use 0...1 scale\nfoxy = foxy.reshape(298 * 203, 3)\nfoxy.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:40.048951Z","iopub.execute_input":"2025-01-19T19:17:40.049299Z","iopub.status.idle":"2025-01-19T19:17:40.078007Z","shell.execute_reply.started":"2025-01-19T19:17:40.049269Z","shell.execute_reply":"2025-01-19T19:17:40.07693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"foxy.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:47.660553Z","iopub.execute_input":"2025-01-19T19:17:47.660861Z","iopub.status.idle":"2025-01-19T19:17:47.666483Z","shell.execute_reply.started":"2025-01-19T19:17:47.660837Z","shell.execute_reply":"2025-01-19T19:17:47.665459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize to (298, 203)\nfoxy_resized = cv2.resize(fox, (203, 298))  # (width, height) for OpenCV\nfoxy = foxy_resized / 255.0\nfoxy = foxy.reshape(298 * 203, 3)\nprint(foxy.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:17:53.199364Z","iopub.execute_input":"2025-01-19T19:17:53.199682Z","iopub.status.idle":"2025-01-19T19:17:53.205507Z","shell.execute_reply.started":"2025-01-19T19:17:53.19966Z","shell.execute_reply":"2025-01-19T19:17:53.204637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"liony.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:00.1053Z","iopub.execute_input":"2025-01-19T19:18:00.105653Z","iopub.status.idle":"2025-01-19T19:18:00.117224Z","shell.execute_reply.started":"2025-01-19T19:18:00.105626Z","shell.execute_reply":"2025-01-19T19:18:00.116104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize the image to (275, 220)\nlion_resized = cv2.resize(lion, (220, 275))  # OpenCV uses (width, height)\nliony = lion_resized / 255.0\nliony = liony.reshape(275 * 220, 3)\nprint(liony.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:06.016124Z","iopub.execute_input":"2025-01-19T19:18:06.016418Z","iopub.status.idle":"2025-01-19T19:18:06.022077Z","shell.execute_reply.started":"2025-01-19T19:18:06.016395Z","shell.execute_reply":"2025-01-19T19:18:06.021242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize the image to (286, 304)\ntiger_resized = cv2.resize(tiger, (304, 286))  # OpenCV uses (width, height)\ntigery = tiger_resized / 255.0\ntigery = tigery.reshape(286 * 304, 3)\nprint(tigery.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:13.774114Z","iopub.execute_input":"2025-01-19T19:18:13.774438Z","iopub.status.idle":"2025-01-19T19:18:13.779763Z","shell.execute_reply.started":"2025-01-19T19:18:13.774415Z","shell.execute_reply":"2025-01-19T19:18:13.779074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize the image to (328, 302)\nwolf_resized = cv2.resize(wolf, (302, 328))  # OpenCV uses (width, height)\nwolfy = wolf_resized / 255.0\nwolfy = wolfy.reshape(328 * 302, 3)\nprint(wolfy.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:19.261886Z","iopub.execute_input":"2025-01-19T19:18:19.262164Z","iopub.status.idle":"2025-01-19T19:18:19.269818Z","shell.execute_reply.started":"2025-01-19T19:18:19.262144Z","shell.execute_reply":"2025-01-19T19:18:19.269052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n# Resize the image to (148, 201)\npanda_resized = cv2.resize(panda, (201, 148))  # OpenCV uses (width, height)\npanday = panda_resized / 255.0\npanday = panday.reshape(148 * 201, 3)\nprint(panday.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:26.828625Z","iopub.execute_input":"2025-01-19T19:18:26.828893Z","iopub.status.idle":"2025-01-19T19:18:26.834033Z","shell.execute_reply.started":"2025-01-19T19:18:26.828874Z","shell.execute_reply":"2025-01-19T19:18:26.833316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Vizualize pixels in color space ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:33.584055Z","iopub.execute_input":"2025-01-19T19:18:33.584354Z","iopub.status.idle":"2025-01-19T19:18:33.589567Z","shell.execute_reply.started":"2025-01-19T19:18:33.584331Z","shell.execute_reply":"2025-01-19T19:18:33.588401Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"visualize pixels in color space","metadata":{}},{"cell_type":"code","source":"def plot_pixels(doggy, title, colors=None, N=10000):\n    if colors is None:\n        colors = doggy\n    \n    # choose a random subset\n    rng = np.random.RandomState(0)\n    i = rng.permutation(doggy.shape[0])[:N]\n    colors = colors[i]\n    R, G, B = doggy[i].T\n    \n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n    ax[0].scatter(R, G, color=colors, marker='.')\n    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n\n    ax[1].scatter(R, B, color=colors, marker='.')\n    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n\n    fig.suptitle(title, size=20);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:40.55674Z","iopub.execute_input":"2025-01-19T19:18:40.55702Z","iopub.status.idle":"2025-01-19T19:18:40.562904Z","shell.execute_reply.started":"2025-01-19T19:18:40.557Z","shell.execute_reply":"2025-01-19T19:18:40.56188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(doggy, title='Input color space: 16 million possible colors')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:50.120199Z","iopub.execute_input":"2025-01-19T19:18:50.12057Z","iopub.status.idle":"2025-01-19T19:18:50.576981Z","shell.execute_reply.started":"2025-01-19T19:18:50.12051Z","shell.execute_reply":"2025-01-19T19:18:50.575675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_pixels(data, title='', colors=None, N=10000):\n    # Ensure data is in the range [0, 1]\n    if data.max() > 1.0:\n        data = data / 255.0\n\n    # Flatten the data into a list of RGB values\n    data = data.reshape(-1, 3)\n\n    # Subsample if data is too large\n    if data.shape[0] > N:\n        np.random.seed(0)  # For reproducibility\n        idx = np.random.choice(data.shape[0], N, replace=False)\n        data = data[idx]\n\n    # Prepare colors for scatter plot\n    if colors is None:\n        colors = data\n\n    # Separate R, G, B channels for scatter plot\n    R, G, B = data[:, 0], data[:, 1], data[:, 2]\n\n    # Plot scatter plot\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n    ax[0].scatter(R, G, c=colors, marker='.', s=1)  # Use `c` for color mapping\n    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n    ax[0].set_title(f\"{title} - RGB space\")\n\n    ax[1].scatter(R, B, c=colors, marker='.', s=1)\n    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n    ax[1].set_title(f\"{title} - Alternate RGB space\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:18:59.174139Z","iopub.execute_input":"2025-01-19T19:18:59.174448Z","iopub.status.idle":"2025-01-19T19:18:59.181189Z","shell.execute_reply.started":"2025-01-19T19:18:59.174428Z","shell.execute_reply":"2025-01-19T19:18:59.1803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(doggy, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:19:08.771773Z","iopub.execute_input":"2025-01-19T19:19:08.772068Z","iopub.status.idle":"2025-01-19T19:19:09.652613Z","shell.execute_reply.started":"2025-01-19T19:19:08.772048Z","shell.execute_reply":"2025-01-19T19:19:09.651693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(doggy.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:19:16.358783Z","iopub.execute_input":"2025-01-19T19:19:16.359098Z","iopub.status.idle":"2025-01-19T19:19:16.363487Z","shell.execute_reply.started":"2025-01-19T19:19:16.359072Z","shell.execute_reply":"2025-01-19T19:19:16.362755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `doggy` is normalized\nif doggy.max() > 1.0:\n    doggy = doggy / 255.0\n\n# Apply KMeans clustering to reduce color space\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(doggy)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(doggy)]\n\n# Define the plot_pixels function\ndef plot_pixels(data, title='', colors=None, N=10000):\n    # Ensure data is in the range [0, 1]\n    if data.max() > 1.0:\n        data = data / 255.0\n\n    # Subsample if data is too large\n    if data.shape[0] > N:\n        np.random.seed(0)  # For reproducibility\n        idx = np.random.choice(data.shape[0], N, replace=False)\n        data = data[idx]\n        colors = colors[idx] if colors is not None else data\n\n    # Prepare colors for scatter plot\n    R, G, B = data[:, 0], data[:, 1], data[:, 2]\n\n    # Plot scatter plot\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n    ax[0].scatter(R, G, c=colors, marker='.', s=1)  # Use `c` for color mapping\n    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n    ax[0].set_title(f\"{title} - RGB space\")\n\n    ax[1].scatter(R, B, c=colors, marker='.', s=1)\n    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n    ax[1].set_title(f\"{title} - Alternate RGB space\")\n\n    plt.tight_layout()\n    plt.show()\n\n# Plot the reduced color space image\nplot_pixels(doggy, colors=new_colors, title=\"Reduced color space: 16 colors\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:19:21.448127Z","iopub.execute_input":"2025-01-19T19:19:21.448428Z","iopub.status.idle":"2025-01-19T19:19:22.732096Z","shell.execute_reply.started":"2025-01-19T19:19:21.448404Z","shell.execute_reply":"2025-01-19T19:19:22.731049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dog_recolored = new_colors.reshape(dog.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(dog)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(dog_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"dog_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:19:29.846456Z","iopub.execute_input":"2025-01-19T19:19:29.846826Z","iopub.status.idle":"2025-01-19T19:19:29.860755Z","shell.execute_reply.started":"2025-01-19T19:19:29.846802Z","shell.execute_reply":"2025-01-19T19:19:29.859414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `dog` is normalized\nif dog.max() > 1.0:\n    dog = dog / 255.0\n\n# Reshape `dog` for KMeans\nheight, width, channels = dog.shape\ndoggy = dog.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(doggy)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(doggy)]\n\n# Reshape `new_colors` back to the original image dimensions\ndog_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(dog)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(dog_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"dog_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:19:49.917259Z","iopub.execute_input":"2025-01-19T19:19:49.91763Z","iopub.status.idle":"2025-01-19T19:19:51.108955Z","shell.execute_reply.started":"2025-01-19T19:19:49.9176Z","shell.execute_reply":"2025-01-19T19:19:51.108017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(foxy, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:20:02.458565Z","iopub.execute_input":"2025-01-19T19:20:02.458872Z","iopub.status.idle":"2025-01-19T19:20:03.303322Z","shell.execute_reply.started":"2025-01-19T19:20:02.458851Z","shell.execute_reply":"2025-01-19T19:20:03.302516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(16)\nkmeans.fit(foxy)\nnew_colors = kmeans.cluster_centers_[kmeans.predict(foxy)]\n\nplot_pixels(foxy, colors=new_colors,\n            title=\"Reduced color space: 16 colors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:20:09.643087Z","iopub.execute_input":"2025-01-19T19:20:09.643384Z","iopub.status.idle":"2025-01-19T19:20:12.043304Z","shell.execute_reply.started":"2025-01-19T19:20:09.643362Z","shell.execute_reply":"2025-01-19T19:20:12.042107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fox_recolored = new_colors.reshape(fox.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(fox)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(fox_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"fox_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:20:30.145793Z","iopub.execute_input":"2025-01-19T19:20:30.14608Z","iopub.status.idle":"2025-01-19T19:20:30.160079Z","shell.execute_reply.started":"2025-01-19T19:20:30.146059Z","shell.execute_reply":"2025-01-19T19:20:30.159063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fox_recolored = new_colors.reshape(fox.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(fox)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(fox_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"fox_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:20:53.329181Z","iopub.execute_input":"2025-01-19T19:20:53.329471Z","iopub.status.idle":"2025-01-19T19:20:53.342732Z","shell.execute_reply.started":"2025-01-19T19:20:53.329449Z","shell.execute_reply":"2025-01-19T19:20:53.341618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `fox` is normalized\nif fox.max() > 1.0:\n    fox = fox / 255.0\n\n# Reshape `fox` for KMeans\nheight, width, channels = fox.shape  # Original image dimensions (922, 1229, 3)\nfox_reshaped = fox.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Check the number of pixels matches\nassert fox_reshaped.shape[0] == (height * width), \"Mismatch in number of pixels!\"\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(fox_reshaped)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(fox_reshaped)]\n\n# Reshape `new_colors` back to the original image dimensions\nfox_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(fox)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(fox_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"fox_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:20:58.825183Z","iopub.execute_input":"2025-01-19T19:20:58.825545Z","iopub.status.idle":"2025-01-19T19:21:01.375409Z","shell.execute_reply.started":"2025-01-19T19:20:58.825504Z","shell.execute_reply":"2025-01-19T19:21:01.374514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(liony, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:08.2672Z","iopub.execute_input":"2025-01-19T19:21:08.26748Z","iopub.status.idle":"2025-01-19T19:21:09.154754Z","shell.execute_reply.started":"2025-01-19T19:21:08.267459Z","shell.execute_reply":"2025-01-19T19:21:09.153847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nimport warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n\nfrom sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(16)\nkmeans.fit(liony)\nnew_colors = kmeans.cluster_centers_[kmeans.predict(liony)]\n\nplot_pixels(liony, colors=new_colors,\n            title=\"Reduced color space: 16 colors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:20.131692Z","iopub.execute_input":"2025-01-19T19:21:20.131972Z","iopub.status.idle":"2025-01-19T19:21:21.24159Z","shell.execute_reply.started":"2025-01-19T19:21:20.131953Z","shell.execute_reply":"2025-01-19T19:21:21.240605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lion_recolored = new_colors.reshape(lion.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(lion)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(lion_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"lion_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:32.248992Z","iopub.execute_input":"2025-01-19T19:21:32.249289Z","iopub.status.idle":"2025-01-19T19:21:32.262768Z","shell.execute_reply.started":"2025-01-19T19:21:32.249267Z","shell.execute_reply":"2025-01-19T19:21:32.261572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `lion` is normalized\nif lion.max() > 1.0:\n    lion = lion / 255.0\n\n# Reshape `lion` for KMeans\nheight, width, channels = lion.shape  # Original image dimensions\nlion_reshaped = lion.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Check the number of pixels matches\nassert lion_reshaped.shape[0] == (height * width), \"Mismatch in number of pixels!\"\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(lion_reshaped)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(lion_reshaped)]\n\n# Reshape `new_colors` back to the original image dimensions\nlion_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(lion)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(lion_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"lion_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:38.693312Z","iopub.execute_input":"2025-01-19T19:21:38.693652Z","iopub.status.idle":"2025-01-19T19:21:40.862844Z","shell.execute_reply.started":"2025-01-19T19:21:38.693627Z","shell.execute_reply":"2025-01-19T19:21:40.861613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(tigery, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:47.895709Z","iopub.execute_input":"2025-01-19T19:21:47.896017Z","iopub.status.idle":"2025-01-19T19:21:48.752607Z","shell.execute_reply.started":"2025-01-19T19:21:47.895995Z","shell.execute_reply":"2025-01-19T19:21:48.751616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n\nfrom sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(16)\nkmeans.fit(tigery)\nnew_colors = kmeans.cluster_centers_[kmeans.predict(tigery)]\n\nplot_pixels(tigery, colors=new_colors,\n            title=\"Reduced color space: 16 colors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:21:55.100267Z","iopub.execute_input":"2025-01-19T19:21:55.10058Z","iopub.status.idle":"2025-01-19T19:21:56.107435Z","shell.execute_reply.started":"2025-01-19T19:21:55.100555Z","shell.execute_reply":"2025-01-19T19:21:56.1066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tiger_recolored = new_colors.reshape(tiger.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(tiger)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(tiger_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"tiger_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:22:03.263492Z","iopub.execute_input":"2025-01-19T19:22:03.263835Z","iopub.status.idle":"2025-01-19T19:22:03.277842Z","shell.execute_reply.started":"2025-01-19T19:22:03.263811Z","shell.execute_reply":"2025-01-19T19:22:03.276591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `tiger` is normalized\nif tiger.max() > 1.0:\n    tiger = tiger / 255.0\n\n# Reshape `tiger` for KMeans\nheight, width, channels = tiger.shape  # Original image dimensions\ntiger_reshaped = tiger.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Check the number of pixels matches\nassert tiger_reshaped.shape[0] == (height * width), \"Mismatch in number of pixels!\"\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(tiger_reshaped)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(tiger_reshaped)]\n\n# Reshape `new_colors` back to the original image dimensions\ntiger_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(tiger)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(tiger_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"tiger_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:22:18.02755Z","iopub.execute_input":"2025-01-19T19:22:18.027846Z","iopub.status.idle":"2025-01-19T19:22:19.794545Z","shell.execute_reply.started":"2025-01-19T19:22:18.027824Z","shell.execute_reply":"2025-01-19T19:22:19.793727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(wolfy, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:22:42.331988Z","iopub.execute_input":"2025-01-19T19:22:42.332266Z","iopub.status.idle":"2025-01-19T19:22:43.057191Z","shell.execute_reply.started":"2025-01-19T19:22:42.332244Z","shell.execute_reply":"2025-01-19T19:22:43.056248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n\nfrom sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(16)\nkmeans.fit(wolfy)\nnew_colors = kmeans.cluster_centers_[kmeans.predict(wolfy)]\n\nplot_pixels(wolfy, colors=new_colors,\n            title=\"Reduced color space: 16 colors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:22:51.74185Z","iopub.execute_input":"2025-01-19T19:22:51.742171Z","iopub.status.idle":"2025-01-19T19:22:52.758362Z","shell.execute_reply.started":"2025-01-19T19:22:51.742144Z","shell.execute_reply":"2025-01-19T19:22:52.757445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wolf_recolored = new_colors.reshape(wolf.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(wolf)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(wolf_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"wolf_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:23:23.531603Z","iopub.execute_input":"2025-01-19T19:23:23.531893Z","iopub.status.idle":"2025-01-19T19:23:23.546988Z","shell.execute_reply.started":"2025-01-19T19:23:23.531872Z","shell.execute_reply":"2025-01-19T19:23:23.545878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `wolf` is normalized\nif wolf.max() > 1.0:\n    wolf = wolf / 255.0\n\n# Reshape `wolf` for KMeans\nheight, width, channels = wolf.shape  # Original image dimensions (1067, 1600, 3)\nwolf_reshaped = wolf.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Check the number of pixels matches\nassert wolf_reshaped.shape[0] == (height * width), \"Mismatch in number of pixels!\"\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(wolf_reshaped)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(wolf_reshaped)]\n\n# Reshape `new_colors` back to the original image dimensions\nwolf_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(wolf)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(wolf_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"wolf_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:23:34.416525Z","iopub.execute_input":"2025-01-19T19:23:34.416847Z","iopub.status.idle":"2025-01-19T19:23:37.8455Z","shell.execute_reply.started":"2025-01-19T19:23:34.416826Z","shell.execute_reply":"2025-01-19T19:23:37.844601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixels(panday, title='Input color space: 16 million possible colors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:24:01.939058Z","iopub.execute_input":"2025-01-19T19:24:01.939394Z","iopub.status.idle":"2025-01-19T19:24:02.800305Z","shell.execute_reply.started":"2025-01-19T19:24:01.939369Z","shell.execute_reply":"2025-01-19T19:24:02.799562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n\nfrom sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(16)\nkmeans.fit(panday)\nnew_colors = kmeans.cluster_centers_[kmeans.predict(wolfy)]\n\nplot_pixels(panday, colors=new_colors,\n            title=\"Reduced color space: 16 colors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:24:39.112426Z","iopub.execute_input":"2025-01-19T19:24:39.112769Z","iopub.status.idle":"2025-01-19T19:24:40.281132Z","shell.execute_reply.started":"2025-01-19T19:24:39.112748Z","shell.execute_reply":"2025-01-19T19:24:40.280187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"panda_recolored = new_colors.reshape(panda.shape)\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(panda)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(panda_recolored)\nax[1].set_title('16-color Image', size=16);\n\n# store to file\nplt.savefig(\"panda_kmean.png\", dpi=125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:26:14.272581Z","iopub.execute_input":"2025-01-19T19:26:14.272871Z","iopub.status.idle":"2025-01-19T19:26:14.286534Z","shell.execute_reply.started":"2025-01-19T19:26:14.272851Z","shell.execute_reply":"2025-01-19T19:26:14.285372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')  # Suppress warnings\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Ensure `panda` is normalized\nif panda.max() > 1.0:\n    panda = panda / 255.0\n\n# Reshape `panda` for KMeans\nheight, width, channels = panda.shape  # Original image dimensions (1600, 1600, 3)\npanda_reshaped = panda.reshape(-1, 3)  # Flatten the image to (n_samples, n_features)\n\n# Check the number of pixels matches\nassert panda_reshaped.shape[0] == (height * width), \"Mismatch in number of pixels!\"\n\n# Apply KMeans clustering\nkmeans = MiniBatchKMeans(n_clusters=16, random_state=42)\nkmeans.fit(panda_reshaped)\n\n# Map each pixel to the nearest cluster center\nnew_colors = kmeans.cluster_centers_[kmeans.predict(panda_reshaped)]\n\n# Reshape `new_colors` back to the original image dimensions\npanda_recolored = new_colors.reshape(height, width, channels)\n\n# Plot the original and recolored images\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),\n                       subplot_kw=dict(xticks=[], yticks=[]))\nfig.subplots_adjust(wspace=0.05)\nax[0].imshow(panda)\nax[0].set_title('Original Image', size=16)\nax[1].imshow(panda_recolored)\nax[1].set_title('16-color Image', size=16)\n\n# Save the output\nplt.savefig(\"panda_kmean.png\", dpi=125)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:26:21.165809Z","iopub.execute_input":"2025-01-19T19:26:21.166133Z","iopub.status.idle":"2025-01-19T19:26:24.498579Z","shell.execute_reply.started":"2025-01-19T19:26:21.166107Z","shell.execute_reply":"2025-01-19T19:26:24.497766Z"}},"outputs":[],"execution_count":null}]}